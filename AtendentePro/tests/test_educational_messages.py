#!/usr/bin/env python3
"""
Teste das mensagens educativas dos guardrails
Verifica se os guardrails retornam mensagens amigÃ¡veis ao invÃ©s de exceÃ§Ãµes
"""

import sys
import os
from pathlib import Path
from unittest.mock import Mock

# Adicionar o diretÃ³rio pai ao path
current_dir = Path(__file__).parent
parent_dir = current_dir.parent
sys.path.insert(0, str(parent_dir))

# Importar mÃ³dulos
from guardrails import (
    reject_off_topic_queries,
    reject_sensitive_content,
    validate_business_codes,
    detect_spam_patterns,
    reject_off_topic_queries_factory
)

def test_educational_messages():
    """Testa se os guardrails retornam mensagens educativas"""
    
    print("ğŸ§ª TESTE: Mensagens Educativas dos Guardrails")
    print("=" * 60)
    
    # Casos de teste para diferentes guardrails
    test_cases = [
        {
            "guardrail": "reject_off_topic_queries",
            "function": reject_off_topic_queries,
            "query": "quem descobriu o brasil?",
            "expected_keywords": ["Desculpe", "nÃ£o posso responder", "reformule"]
        },
        {
            "guardrail": "reject_sensitive_content", 
            "function": reject_sensitive_content,
            "query": "como fazer fraude de IVA?",
            "expected_keywords": ["Desculpe", "conteÃºdo sensÃ­vel", "reformule"]
        },
        {
            "guardrail": "validate_business_codes",
            "function": validate_business_codes,
            "query": "qual o cÃ³digo IVA Z9?",
            "expected_keywords": ["Desculpe", "cÃ³digo", "nÃ£o Ã© vÃ¡lido", "verifique"]
        },
        {
            "guardrail": "detect_spam_patterns",
            "function": detect_spam_patterns,
            "query": "aaaaa",
            "expected_keywords": ["Desculpe", "muito curta", "mais detalhes"]
        }
    ]
    
    success_count = 0
    
    for case in test_cases:
        print(f"\nğŸ“‹ Testando: {case['guardrail']}")
        print(f"   Query: '{case['query']}'")
        print("-" * 40)
        
        # Simular dados
        args = f'{{"query": "{case["query"]}"}}'
        mock_data = Mock()
        mock_data.context = Mock()
        mock_data.context.tool_arguments = args
        
        try:
            # Executar guardrail
            result = case["function"](mock_data)
            
            # Verificar se retornou mensagem educativa
            if result.output_info:
                message = result.output_info
                print(f"   âœ… Mensagem: {message}")
                
                # Verificar se contÃ©m palavras-chave esperadas
                contains_expected = all(
                    keyword.lower() in message.lower() 
                    for keyword in case["expected_keywords"]
                )
                
                if contains_expected:
                    print(f"   âœ… ContÃ©m palavras educativas esperadas")
                    success_count += 1
                else:
                    print(f"   âŒ NÃ£o contÃ©m palavras educativas esperadas")
                    print(f"   Esperado: {case['expected_keywords']}")
            else:
                print(f"   âŒ Nenhuma mensagem retornada")
                
        except Exception as e:
            print(f"   âŒ Erro: {str(e)}")
    
    print(f"\nğŸ“Š Resultado: {success_count}/{len(test_cases)} guardrails com mensagens educativas")
    return success_count == len(test_cases)

def test_agent_specific_messages():
    """Testa mensagens especÃ­ficas por agente"""
    
    print("\nğŸ§ª TESTE: Mensagens EspecÃ­ficas por Agente")
    print("=" * 60)
    
    agents_to_test = [
        "Confirmation Agent",
        "Knowledge Agent", 
        "Usage Agent"
    ]
    
    success_count = 0
    
    for agent_name in agents_to_test:
        print(f"\nğŸ“‹ Testando: {agent_name}")
        print("-" * 40)
        
        # Criar guardrail especÃ­fico do agente
        agent_guardrail = reject_off_topic_queries_factory(agent_name)
        
        # Simular dados com tema fora do escopo
        args = '{"query": "quem descobriu o brasil?"}'
        mock_data = Mock()
        mock_data.context = Mock()
        mock_data.context.tool_arguments = args
        
        try:
            # Executar guardrail especÃ­fico do agente
            result = agent_guardrail(mock_data)
            
            if result.output_info:
                message = result.output_info
                print(f"   âœ… Mensagem: {message}")
                
                # Verificar se menciona o agente especÃ­fico
                agent_friendly = agent_name.replace(" Agent", "").lower()
                if agent_friendly in message.lower():
                    print(f"   âœ… Menciona agente especÃ­fico: {agent_friendly}")
                    success_count += 1
                else:
                    print(f"   âŒ NÃ£o menciona agente especÃ­fico")
            else:
                print(f"   âŒ Nenhuma mensagem retornada")
                
        except Exception as e:
            print(f"   âŒ Erro: {str(e)}")
    
    print(f"\nğŸ“Š Resultado: {success_count}/{len(agents_to_test)} agentes com mensagens especÃ­ficas")
    return success_count == len(agents_to_test)

if __name__ == "__main__":
    print("ğŸ›¡ï¸ TESTE DAS MENSAGENS EDUCATIVEAS DOS GUARDRAILS")
    print("=" * 80)
    
    test1_success = test_educational_messages()
    test2_success = test_agent_specific_messages()
    
    print("\n" + "=" * 80)
    print("ğŸ“‹ RESUMO DO TESTE")
    print("=" * 80)
    
    if test1_success and test2_success:
        print("âœ… TODOS OS TESTES PASSARAM!")
        print("âœ… Guardrails retornam mensagens educativas")
        print("âœ… Mensagens sÃ£o especÃ­ficas por agente")
        print("âœ… UsuÃ¡rio recebe orientaÃ§Ãµes claras")
    else:
        print("âŒ ALGUNS TESTES FALHARAM")
        print("ğŸ”§ Verificar implementaÃ§Ã£o das mensagens educativas")
    
    print("=" * 80)
